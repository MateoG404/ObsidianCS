
## What is the [[Entropy]]?

The [[Entropy]] is the measure of the mean of [[Information Content]] in the original data origin

$H_{x} = -\sum_{i=1}^{m}P(x_i)I(x_i) = -\sum_{i=1}^{m}P(x_i)log_{2}(P_x)$

Where :
	$Hx$ Is the [[Entropy]]

The [[Entropy]] has the rule 

$0 \leq  H_{x} \leq log_{2}(m)$


* The minimum entropy (0) indicates that the system always return the same character
* The maximum entropy ($log_{2}$) indicates all the symbols always are returned with the same probabilty
* 